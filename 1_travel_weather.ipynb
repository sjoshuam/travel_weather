{
 "cells": [
  {
   "cell_type": "raw",
   "id": "78d5d60d-1af9-4e44-87cb-3a6b3dd18e18",
   "metadata": {},
   "source": [
    "0. Import Data – Import all needed data.  This is a large task.\n",
    "1. Refine Data – Clean and reshape data into an enriched form.\n",
    "2. Build Model – Trained a model to predict the weather at destinations.\n",
    "3. Model Routes – Predict weather at destinations along the route.\n",
    "4. Render Visualization – Visualize weather temperateness for each route.\n",
    "5. Test Code - Tests for all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778be4aa-e671-4279-a6cc-24ec56d88ced",
   "metadata": {},
   "source": [
    "# Libraries and Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2a9ee-47c8-4e1f-86ed-e90e8c79e8dc",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96bfe8c1-b00a-45c5-b622-242563a6a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########==========\n",
    "\n",
    "## general purpose libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as url\n",
    "\n",
    "from datetime       import datetime\n",
    "from bs4            import BeautifulSoup\n",
    "from os             import listdir, mkdir\n",
    "from os.path        import isdir, isfile\n",
    "from geopy.distance import distance\n",
    "\n",
    "\n",
    "## time stamp functions\n",
    "set_timing = dict()\n",
    "def time_check(id_str = 'ZZ'):\n",
    "    raw_time = datetime.now()\n",
    "    current_time = [raw_time.hour, raw_time.minute, round(raw_time.second)]\n",
    "    current_time = [str(i).zfill(2) for i in current_time]\n",
    "    current_time = ':'.join(current_time)\n",
    "    current_time = 'Time Check ' + id_str.ljust(4) + ' = ' + current_time\n",
    "    set_timing[id_str] = current_time\n",
    "    if id_str == 'ZZ':\n",
    "        for i in set_timing:\n",
    "            print(set_timing[i])\n",
    "\n",
    "time_check('AA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536436a-2dd9-435b-9561-037d68df7480",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab7de13-3263-431a-8de4-6c12ce36c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## url source of the data\n",
    "set_url = \"https://www.ncei.noaa.gov/data/local-climatological-data/access/{0}/\"\n",
    "set_year = range(2012, 2022)\n",
    "set_prefix = ['69', '72', '74', '91', '99']\n",
    "\n",
    "## cache settings\n",
    "set_dev_mode = True\n",
    "set_cache = {'hard_reset': False, 'testing': True, 'station_roster': True,\n",
    "             'collection' : True,  'compilation': True, 'modeling': True}\n",
    "\n",
    "## defines dtype for the columns in the raw weather data files\n",
    "set_col_list = {'DATE':str, 'LATITUDE':float,\n",
    "    'LONGITUDE':float, 'ELEVATION':float,\n",
    "    \"HourlyDryBulbTemperature\":float,\n",
    "    \"HourlyPrecipitation\":float}\n",
    "\n",
    "## set modeling parameters\n",
    "set_param = {'window': 14, 'mid_summer': 213}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630bfdf-3734-4605-87d0-0e5671ac35d3",
   "metadata": {},
   "source": [
    "#### set up file system (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c478cc19-470a-4b9e-8f12-19da7a63fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make directories that script expects\n",
    "def make_directories():\n",
    "    all_dirs = ['A_Input', 'B_Process', 'C_Output']\n",
    "    all_dirs = all_dirs + ['B_Process/downloads']\n",
    "    for i in all_dirs:\n",
    "        if not isdir(i): mkdir(i)\n",
    "        \n",
    "make_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836ea5b-e330-4de0-bb0c-a7dd64d6a097",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf07b37-777b-4ae9-b591-d72056be7f19",
   "metadata": {},
   "source": [
    "#### retrieve city roster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f2f34b-bca8-4a2d-8f32-e8e934ae9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_roster = pd.read_excel('A_Input/city_list.xlsx',\n",
    "    usecols = {'City': str, 'Route': str, 'lon': float, 'lat': float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108940fa-42b4-46cf-b7e6-8b317617cf52",
   "metadata": {},
   "source": [
    "#### retrieve links page for first year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490866ba-715d-4ded-887d-756871df8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_roster(the_year, the_url = set_url, valid_prefix = set_prefix):\n",
    "  \n",
    "    ## retrive raw web page\n",
    "    the_url = the_url.format(the_year)\n",
    "    with url.urlopen(the_url) as conn:\n",
    "        all_files = conn.read()\n",
    "        conn.close()\n",
    "        \n",
    "    ## extract links to csv files\n",
    "    all_files = BeautifulSoup(all_files)\n",
    "    all_files = all_files.find_all('a')\n",
    "    all_files = [i.string for i in all_files if i.string.find('.csv') != -1]\n",
    "        \n",
    "    ## package as pandas files; limit to valid prefix\n",
    "    all_files = pd.DataFrame({'prefix':0, 'file':all_files,\n",
    "                              'lon': np.nan, 'lat': np.nan, 'dist': np.nan})\n",
    "    all_files['prefix'] = [i[0:2] for i in all_files['file']]\n",
    "    all_files = all_files[all_files.prefix.isin(valid_prefix)]\n",
    "    all_files = all_files.reset_index()\n",
    "\n",
    "    del all_files['index']\n",
    "    \n",
    "    return all_files \n",
    "\n",
    "## execute code\n",
    "data_roster = make_data_roster(set_year[-1])\n",
    "if set_dev_mode: data_roster = data_roster.loc[0:9, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d7862-e61e-48a3-812c-5aef172d8dbf",
   "metadata": {},
   "source": [
    "#### determine which stations are near route cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0b283f-24fe-49ef-b186-ba4fb739fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_station_data(x, ucl = set_col_list):\n",
    "    the_csv = pd.read_csv(x, usecols = ucl, parse_dates = ['DATE'], dtype = str)\n",
    "    for j in ucl.keys():\n",
    "        if ucl[j] == float:\n",
    "            the_csv[j] = pd.to_numeric(the_csv[j], errors = 'coerce')\n",
    "    return the_csv\n",
    "\n",
    "def filter_to_proximate_data(\n",
    "    dat_rost = data_roster, the_url = set_url, city = city_roster):\n",
    "    \n",
    "    for i in dat_rost.index:\n",
    "        \n",
    "        ## download file and coerce numeric columns to numeric\n",
    "        full_url = set_url.format(set_year[-1]) + dat_rost.loc[i, 'file']\n",
    "        the_csv = read_station_data(full_url)\n",
    "        \n",
    "        ## find distance to closest rostered metro area\n",
    "        min_dist = 999999\n",
    "        for j in city.index:\n",
    "            dist_j = distance(\n",
    "                tuple(the_csv.loc[0, ['LATITUDE', 'LONGITUDE']]),\n",
    "                tuple(city.loc[j, ['lat', 'lon']])).miles\n",
    "            min_dist = min(min_dist, dist_j)\n",
    "        dat_rost.loc[i, 'dist'] = np.round(min_dist)\n",
    "        \n",
    "    ## save roster file to disk\n",
    "    dat_rost.to_csv('B_Process/station_roster.csv')\n",
    "    return dat_rost\n",
    "    \n",
    "if not set_cache['station_roster'] or not isfile('B_Process/station_roster.csv'):\n",
    "    station_roster = filter_to_proximate_data()\n",
    "else:\n",
    "    station_roster = pd.read_csv('B_Process/station_roster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2922e14-8c66-455f-8ba3-ae2aa89c15e4",
   "metadata": {},
   "source": [
    "#### retrieve data from subsequent years for proximate stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2629af6-0762-432a-8b66-4c2f57e4722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_station_data(\n",
    "    roster = station_roster, url = set_url, year = set_year, ucl = set_col_list):\n",
    "    \n",
    "    ## download all relavent data files\n",
    "    for i in year:\n",
    "        if not str(i) in roster.columns: roster[str(i)] = False\n",
    "        needed_file = (roster.dist < 30) & ~roster[str(i)]\n",
    "        for j in roster.index[needed_file]:\n",
    "            ## download data file\n",
    "            try:\n",
    "                error_flag = False\n",
    "                x = read_station_data(url.format(i) + roster.loc[j, 'file'])\n",
    "                if i == year[0]:\n",
    "                    roster.loc[j, 'lon'] = x.loc[0, 'LONGITUDE']\n",
    "                    roster.loc[j, 'lat'] = x.loc[0, 'LATITUDE']\n",
    "                x.to_csv(\n",
    "                    'B_Process/downloads/' + str(i) + '_'+ roster.loc[j, 'file'])\n",
    "            except:\n",
    "                error_flag = True\n",
    "            \n",
    "            ## update roster\n",
    "            if error_flag: roster.loc[j, str(i)] = False\n",
    "            else: roster.loc[j, str(i)] = True\n",
    "            roster.to_csv('B_Process/station_roster.csv')\n",
    "\n",
    "retrieve_station_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bd876-4fc2-45d1-a41d-6e23cb75fb63",
   "metadata": {},
   "source": [
    "#### record completion time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec88b623-7352-45ed-addd-3632dac6f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54b404-eaa6-4743-8181-caced638143c",
   "metadata": {},
   "source": [
    "# Refine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b858194d-9ad8-4823-b5cf-05b8ebb7c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check('RD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5c69-1550-4b74-ae27-a3f206d3dc1c",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6fc873-c3c2-4f79-9615-ad6125499c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check('BM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366c932-ce0d-44da-aa7f-8cda8c66c8fb",
   "metadata": {},
   "source": [
    "# Model Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2887dbc7-fa59-4dc0-9f2e-4a58e5119c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check('MR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b220a9-e4c8-4498-8219-7855ba983845",
   "metadata": {},
   "source": [
    "# Render Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a1f5c76-8a6a-4edb-afa2-6e6302713e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check('RV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23023019-0f8e-4cc7-b266-ccb6fe20f7b1",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9c6ff3-02a3-4b1d-91e9-acfc85b54b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check('TC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de2aab-a8a1-4dff-bd0a-bd051ca73d52",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a350ac31-ae36-4b98-9865-a387f256cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Check AA   = 09:35:06\n",
      "Time Check ID   = 09:36:05\n",
      "Time Check RD   = 09:36:05\n",
      "Time Check BM   = 09:36:05\n",
      "Time Check MR   = 09:36:05\n",
      "Time Check RV   = 09:36:05\n",
      "Time Check TC   = 09:36:05\n",
      "Time Check ZZ   = 09:36:05\n"
     ]
    }
   ],
   "source": [
    "## Display time statistics\n",
    "time_check('ZZ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
