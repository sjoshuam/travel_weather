{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f664f8-58d2-4415-82d6-f2ad15f77268",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########----------##########----------##########----------##########----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf05299-44af-42e4-9e1b-cf5a7be27e91",
   "metadata": {},
   "source": [
    "# Libraries, setup, and general use objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6174b868-46b2-4ab1-a0d1-18881bf2dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as url\n",
    "import pandas as pd\n",
    "import ipyparallel as ipp\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from os import listdir, mkdir\n",
    "from os.path import isdir\n",
    "from sklearn import\n",
    "\n",
    "set_gather_data = False\n",
    "\n",
    "##\n",
    "valid_prefix = [69, 72, 74, 99]\n",
    "use_col_list = {'DATE':str, 'LATITUDE':float, 'LONGITUDE':float,\n",
    "    'ELEVATION':float, \"HourlyDryBulbTemperature\":float,\n",
    "                \"HourlyPrecipitation\":float} # \"HourlyRelativeHumidity\":float,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcc824-50a7-4b00-9ca2-dca03ba27d03",
   "metadata": {},
   "source": [
    "#### Generate directories as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1282f5a0-7fb2-4813-9b4c-118e866916fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories():\n",
    "    all_dirs = ['A_Input', 'B_Process', 'C_Output']\n",
    "    all_dirs = all_dirs + ['B_Process/downloads', 'B_Process/model_data']\n",
    "    for i in all_dirs:\n",
    "        if not isdir(i): mkdir(i)\n",
    "        \n",
    "make_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d709e-a93a-4467-944a-6fc491586579",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293069b-6f3c-4db1-83e2-e2a2680497b7",
   "metadata": {},
   "source": [
    "#### read_year_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe681d5f-4ab4-43a3-8e88-8cfc99f45508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_year_links(dir_address = 'A_Input/year_links.txt'):\n",
    "    the_connection = open(dir_address, 'r')\n",
    "    year_links = the_connection.readlines()\n",
    "    the_connection.close()\n",
    "    year_links = [i.strip() for i in year_links]\n",
    "    return year_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4c2ff-ed58-4515-be38-d44b4003f654",
   "metadata": {},
   "source": [
    "#### extract_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b86605-4ec2-4a33-ab43-5029b5c911d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_links(address):\n",
    "    \n",
    "    ## retrieve raw web page\n",
    "    url_connect = url.urlopen(address)\n",
    "    all_links = url_connect.read()\n",
    "    url_connect.close()\n",
    "    \n",
    "    ## extract all links to csv files\n",
    "    all_links = BeautifulSoup(all_links)\n",
    "    all_links = all_links.find_all('a')\n",
    "    all_links = [i.string for i in all_links if i.string.find('.csv') != -1]\n",
    "    \n",
    "    ## eliminate files unlikely to represent US weather stations\n",
    "    def us_range(x, target_range = valid_prefix):\n",
    "        try:\n",
    "            int(x[0:2])\n",
    "        except:\n",
    "            return False\n",
    "        if int(x[0:2]) in target_range:\n",
    "            return True\n",
    "        else:\n",
    "             return False\n",
    "    all_links = filter(us_range, all_links)\n",
    "    \n",
    "    ## remove url if files have already been downloaded\n",
    "    already_downloaded = listdir('B_Process/downloads')\n",
    "    valid_links = list()\n",
    "    for i in all_links:\n",
    "        if address[-5:-1] + '_' + i + '.gz' in already_downloaded:\n",
    "            pass\n",
    "        else:\n",
    "            x = address[-5:-1] + '_' + i + '.gz'\n",
    "            y = address + i\n",
    "            valid_links.append((x, y))\n",
    "            \n",
    "    return valid_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37744d-eb60-44e8-a500-f15b36a88504",
   "metadata": {},
   "source": [
    "#### download_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163e0c2b-1c70-4e44-a6d0-1215441eea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(links_ext, ucl = use_col_list):\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        the_csv = pd.read_csv(links_ext[1], usecols = list(ucl.keys()),\n",
    "            parse_dates = ['DATE'], dtype = ucl)\n",
    "    except:\n",
    "        the_csv = pd.read_csv(links_ext[1], usecols = list(ucl.keys()),\n",
    "            parse_dates = ['DATE'], dtype = str)\n",
    "        for j in ucl.keys():\n",
    "            if ucl[j] == float:\n",
    "                the_csv[j] = pd.to_numeric(the_csv[j], errors = 'coerce')\n",
    "        \n",
    "    the_csv = the_csv.round(3)\n",
    "    the_csv.to_csv('B_Process/downloads/' + links_ext[0], encoding = 'utf-8',\n",
    "                    index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36cb1a-4b4b-44d7-b343-0073e50c9a54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Execute code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e20343e-6dcb-450b-921e-f08e85bfcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_gather_data:\n",
    "\n",
    "    ## read in list of links to file directory pages for each year of the data\n",
    "    year_links = read_year_links()\n",
    "\n",
    "    ## iterative extract files from the links on each directory page\n",
    "    for i in year_links:\n",
    "        links_extracted = extract_links(i)\n",
    "    \n",
    "        with ipp.Cluster(n = 4) as rc:\n",
    "            par_processes = rc.load_balanced_view()\n",
    "            par_result = par_processes.map_async(download_files, links_extracted)\n",
    "            par_result.wait_interactive()\n",
    "            final_result = par_result.get()\n",
    "\n",
    "    del par_processes, par_result, final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529ee97-e732-4edc-9c03-18abab2615b1",
   "metadata": {},
   "source": [
    "# Refine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be5d38-1b2a-4539-9f56-017b592c3866",
   "metadata": {},
   "source": [
    "#### refine_data (and compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49da520a-dcec-4c76-b23d-4aede2035515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_data(file_dir, segment, ucl = use_col_list):\n",
    "    \n",
    "    ## generate roster of files\n",
    "    list_files = listdir(file_dir)\n",
    "    list_files = [i for i in list_files if i[0] != '.']\n",
    "    \n",
    "    ## filter files to specified segment\n",
    "    def us_range(x, target_range = segment):\n",
    "        try:\n",
    "            x[0:7]\n",
    "        except:\n",
    "            return False\n",
    "        if x[0:7] in target_range:\n",
    "            return True\n",
    "        else:\n",
    "             return False\n",
    "    list_files = filter(us_range, list_files)\n",
    "    \n",
    "    ## assemble files\n",
    "    all_data = list()\n",
    "    for i in list_files:\n",
    "        file_iter = pd.read_csv(file_dir + '/' + i, parse_dates = ['DATE'],\n",
    "                                dtype = ucl)\n",
    "        \n",
    "        ## deconstruct day/times\n",
    "        file_iter['Day'] = file_iter['DATE'].dt.dayofyear\n",
    "        file_iter['Hour'] = file_iter['DATE'].dt.hour\n",
    "        file_iter = file_iter.drop('DATE', axis = 1)\n",
    "        \n",
    "        ## score weather\n",
    "        file_iter['HourlyPrecipitation'] = file_iter[\n",
    "            'HourlyPrecipitation'].fillna(0)\n",
    "        file_iter['Temperate'] = (file_iter['HourlyDryBulbTemperature'] > 55) &\\\n",
    "            (file_iter['HourlyDryBulbTemperature'] < 75) &\\\n",
    "            (file_iter['HourlyPrecipitation'] < 0.1)\n",
    "        file_iter['Temperate'] = file_iter['Temperate'].astype(int)\n",
    "        file_iter = file_iter.drop(['HourlyDryBulbTemperature',\n",
    "            'HourlyPrecipitation'], axis = 1)\n",
    "        \n",
    "        ## rename columns to make capitalization consistent\n",
    "        file_iter = file_iter.rename(columns = {'LATITUDE':'Lat',\n",
    "            'LONGITUDE': 'Lon', 'ELEVATION':\"Elev\"})\n",
    "        \n",
    "        ## drop files outside the US's rough lat/lon box\n",
    "        if max(file_iter.Lat) > 25 and min(file_iter.Lat) < 50:\n",
    "            if max(file_iter.Lon) < -60 and min(file_iter.Lon) > -130:\n",
    "                all_data.append(file_iter)\n",
    "    \n",
    "    ## compile files and save\n",
    "    if len(all_data) > 0:\n",
    "        all_data = pd.concat(all_data, axis = 0)\n",
    "        all_data.to_csv('B_Process/model_data/' + str(segment[0]) +\\\n",
    "            '_weather_data.csv.gz', index = False, encoding = 'utf-8')\n",
    "        return all_data\n",
    "    else:\n",
    "        pass\n",
    "        #print('WARNING: ' + str(segment[0]) + ' files contain no valid data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3348c2-11a4-4644-89db-64ddbf6af7db",
   "metadata": {},
   "source": [
    "#### Execute Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "039fa2fb-b1e0-4eae-9cdf-68505a3a5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_gather_data:\n",
    "    for i in valid_prefix:\n",
    "        for j in range(2010, 2020):\n",
    "            segment_iter = [str(j) + '_' + str(i)]\n",
    "            refine_data('B_Process/downloads', segment = segment_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad05bf5-0483-4eab-9eec-d5b4031727d2",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca0fae-d284-4668-b492-c09354b59035",
   "metadata": {},
   "source": [
    "#### load_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "457638df-f721-4ce1-b4aa-9b8ce66168cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data(file_directory = 'B_Process/model_data'):\n",
    "    all_data = listdir(file_directory)\n",
    "    all_data = [i for i in all_data if i[-6:] == 'csv.gz']\n",
    "    for i in range(len(all_data)):\n",
    "        all_data[i] = pd.read_csv(file_directory + '/' + all_data[i])\n",
    "    all_data = pd.concat(all_data, axis = 0)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3eed6-55cb-4dbd-b855-08f38911dcd8",
   "metadata": {},
   "source": [
    "#### train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a12a3d6-8a70-4f2c-8ffc-e24127c8c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e9ea6-f04d-43dd-8cf9-517192460ad8",
   "metadata": {},
   "source": [
    "#### Execute Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d08b91f7-208e-48ee-adcd-45b902ec5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = load_model_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddf3c4-792a-4f0d-90a7-94d631ffb412",
   "metadata": {},
   "source": [
    "# Model Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10a86b9f-385e-467e-bc11-cfe257b08e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Elev</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.05</td>\n",
       "      <td>-94.401</td>\n",
       "      <td>108.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.05</td>\n",
       "      <td>-94.401</td>\n",
       "      <td>108.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.05</td>\n",
       "      <td>-94.401</td>\n",
       "      <td>108.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.05</td>\n",
       "      <td>-94.401</td>\n",
       "      <td>108.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.05</td>\n",
       "      <td>-94.401</td>\n",
       "      <td>108.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715676</th>\n",
       "      <td>44.65</td>\n",
       "      <td>-73.467</td>\n",
       "      <td>71.3</td>\n",
       "      <td>365</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715677</th>\n",
       "      <td>44.65</td>\n",
       "      <td>-73.467</td>\n",
       "      <td>71.3</td>\n",
       "      <td>365</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715678</th>\n",
       "      <td>44.65</td>\n",
       "      <td>-73.467</td>\n",
       "      <td>71.3</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715679</th>\n",
       "      <td>44.65</td>\n",
       "      <td>-73.467</td>\n",
       "      <td>71.3</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715680</th>\n",
       "      <td>44.65</td>\n",
       "      <td>-73.467</td>\n",
       "      <td>71.3</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46160232 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lat     Lon   Elev  Day  Hour  Temperate\n",
       "0         34.05 -94.401  108.2    1     0          0\n",
       "1         34.05 -94.401  108.2    1     0          0\n",
       "2         34.05 -94.401  108.2    1     1          0\n",
       "3         34.05 -94.401  108.2    1     1          0\n",
       "4         34.05 -94.401  108.2    1     1          0\n",
       "...         ...     ...    ...  ...   ...        ...\n",
       "33715676  44.65 -73.467   71.3  365    21          0\n",
       "33715677  44.65 -73.467   71.3  365    22          0\n",
       "33715678  44.65 -73.467   71.3  365    23          0\n",
       "33715679  44.65 -73.467   71.3  365    23          0\n",
       "33715680  44.65 -73.467   71.3  365    23          0\n",
       "\n",
       "[46160232 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LogisticRegression\n",
    "## PLSRegression\n",
    "## SVR\n",
    "## DecisionTreeRegressor\n",
    "## RandomForestRegressor\n",
    "## MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24382e0-9187-4470-8e3b-6969112a5d6e",
   "metadata": {},
   "source": [
    "# Render Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b11fe-85ea-416c-a344-e205fee52707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
